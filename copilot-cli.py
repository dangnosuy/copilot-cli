#!/usr/bin/env python3
"""
GitHub Copilot Chat CLI Tool
=============================
Tool g·ªçi API ƒë·∫øn c√°c m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn c·ªßa GitHub Copilot.

Lu·ªìng ho·∫°t ƒë·ªông:
1. Nh·∫≠p GitHub token (gho_xxx)
2. L·∫•y Copilot token th√¥ng qua API
3. Xem danh s√°ch models (/models)
4. Ch·ªçn model v√† b·∫Øt ƒë·∫ßu chat

Commands:
  /models       - Xem danh s√°ch models c√≥ s·∫µn
  /select <id>  - Ch·ªçn model theo s·ªë ho·∫∑c ID (vd: /select 1, /select gpt-4o)
  /info         - Xem th√¥ng tin model ƒëang d√πng
  /system       - Xem/ch·ªânh s·ª≠a system prompt
  /clear        - X√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i
  /history      - Xem l·ªãch s·ª≠ h·ªôi tho·∫°i
  /mcp          - Xem danh s√°ch MCP tools
  /mcp add <dir>- Th√™m th∆∞ m·ª•c cho MCP Filesystem
  /mcp fetch    - Th√™m Fetch Server (t·∫£i web)
  /mcp shell    - Th√™m Shell Server (ch·∫°y terminal)
  /mcp auto     - Th√™m t·∫•t c·∫£ MCP servers
  /mcp stop     - D·ª´ng t·∫•t c·∫£ MCP servers
  /help         - Xem h∆∞·ªõng d·∫´n
  /exit         - Tho√°t
"""

import json
import sys
import os
import time
import textwrap
import io
import uuid
import hashlib

# ƒê·∫£m b·∫£o stdout xu·∫•t UTF-8 ƒë√∫ng c√°ch
if hasattr(sys.stdout, 'reconfigure'):
    sys.stdout.reconfigure(encoding='utf-8')
elif sys.stdout.encoding != 'utf-8':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

try:
    import requests
except ImportError:
    print("[!] C·∫ßn c√†i ƒë·∫∑t th∆∞ vi·ªán requests: pip install requests")
    sys.exit(1)

try:
    from mcp_client import MCPManager
except ImportError:
    MCPManager = None


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# CONSTANTS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
GITHUB_API = "https://api.github.com"
COPILOT_TOKEN_ENDPOINT = "/copilot_internal/v2/token"
GITHUB_API_VERSION = "2025-04-01"
COPILOT_API_VERSION = "2025-07-16"
USER_AGENT = "GitHubCopilotChat/0.31.5"

# Colors
class C:
    RESET   = "\033[0m"
    BOLD    = "\033[1m"
    DIM     = "\033[2m"
    RED     = "\033[91m"
    GREEN   = "\033[92m"
    YELLOW  = "\033[93m"
    BLUE    = "\033[94m"
    MAGENTA = "\033[95m"
    CYAN    = "\033[96m"
    WHITE   = "\033[97m"


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# SMART INPUT ‚Äî Inline autocomplete cho / commands
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
import tty
import termios
import select as _select

# Commands cho autocomplete
SLASH_COMMANDS = [
    "/models", "/select", "/info", "/system", "/system set", "/system reset",
    "/clear", "/history", "/mcp", "/mcp add", "/mcp fetch", "/mcp shell",
    "/mcp auto", "/mcp stop", "/token", "/refresh", "/help", "/exit",
]

# Model IDs ‚Äî c·∫≠p nh·∫≠t runtime khi fetch_models
_model_ids_for_complete: list[str] = []


def _get_suggestions(text: str) -> list[str]:
    """Tr·∫£ v·ªÅ danh s√°ch g·ª£i √Ω d·ª±a tr√™n text ƒëang g√µ."""
    if not text.startswith("/"):
        return []

    # /select <arg> ‚Üí g·ª£i √Ω s·ªë ho·∫∑c t√™n model
    if text.startswith("/select "):
        arg = text[8:]
        suggestions = []
        for i, mid in enumerate(_model_ids_for_complete, 1):
            if not arg:
                suggestions.append(f"/select {i}  {C.DIM}({mid}){C.RESET}")
            elif arg.isdigit() and str(i).startswith(arg):
                suggestions.append(f"/select {i}  {C.DIM}({mid}){C.RESET}")
            elif mid.lower().startswith(arg.lower()):
                suggestions.append(f"/select {mid}")
        return suggestions[:8]  # Max 8 g·ª£i √Ω

    # / commands
    matches = [cmd for cmd in SLASH_COMMANDS if cmd.startswith(text)]
    # Ch·ªâ hi·ªán t·ªëi ƒëa 10 g·ª£i √Ω
    return matches[:10]


def _smart_input(prompt: str) -> str:
    """Input v·ªõi inline autocomplete popup cho / commands.

    - G√µ / ‚Üí hi·ªán g·ª£i √Ω b√™n d∆∞·ªõi
    - G√µ th√™m ch·ªØ ‚Üí thu h·∫πp g·ª£i √Ω
    - Tab ‚Üí ch·ªçn g·ª£i √Ω ƒë·∫ßu ti√™n
    - ‚Üë/‚Üì ‚Üí duy·ªát history
    - Enter ‚Üí submit
    - Backspace ‚Üí x√≥a
    - Ctrl+C ‚Üí raise KeyboardInterrupt
    """
    fd = sys.stdin.fileno()
    old_settings = termios.tcgetattr(fd)

    buf = []        # K√Ω t·ª± ƒëang g√µ
    cursor = 0      # V·ªã tr√≠ con tr·ªè trong buf
    prev_suggestion_lines = 0  # S·ªë d√≤ng g·ª£i √Ω ƒëang hi·ªÉn th·ªã
    prev_total_lines = 0       # T·ªïng s·ªë d√≤ng v·∫≠t l√Ω (prompt+text) l·∫ßn v·∫Ω tr∆∞·ªõc

    # History
    if not hasattr(_smart_input, "_history"):
        _smart_input._history = []
    history = _smart_input._history
    hist_idx = len(history)  # B·∫Øt ƒë·∫ßu ·ªü cu·ªëi (d√≤ng m·ªõi)
    saved_buf = None  # L∆∞u d√≤ng ƒëang g√µ khi duy·ªát history

    import re as _re

    def _visible_len(s: str) -> int:
        """T√≠nh ƒë·ªô d√†i hi·ªÉn th·ªã (b·ªè ANSI escape codes)."""
        return len(_re.sub(r'\033\[[^m]*m', '', s))

    def _get_term_width() -> int:
        try:
            return os.get_terminal_size().columns
        except OSError:
            return 80

    # Track the physical line the cursor is on (0-based from the first prompt line)
    # After _redraw(), this is updated to reflect cursor's actual physical line.
    _cursor_phys_line = [0]

    def _redraw():
        nonlocal prev_suggestion_lines, prev_total_lines
        text = "".join(buf)
        term_w = _get_term_width()
        prompt_vis = _visible_len(prompt)

        # T√≠nh s·ªë d√≤ng v·∫≠t l√Ω m√† prompt+text chi·∫øm
        total_visible = prompt_vis + len(text)
        cur_lines = max(1, (total_visible + term_w - 1) // term_w)

        # === B∆∞·ªõc 1: Di chuy·ªÉn con tr·ªè v·ªÅ d√≤ng ƒë·∫ßu ti√™n c·ªßa prompt ===
        up_from_cursor = _cursor_phys_line[0]
        if up_from_cursor > 0:
            sys.stdout.write(f"\033[{up_from_cursor}A")

        # === B∆∞·ªõc 2: X√≥a t·ª´ ƒë·∫ßu d√≤ng prompt ƒë·∫øn h·∫øt m√†n h√¨nh ===
        sys.stdout.write("\r\033[J")

        # === B∆∞·ªõc 3: V·∫Ω l·∫°i prompt + text ===
        sys.stdout.write(prompt)
        sys.stdout.write(text)

        prev_total_lines = cur_lines
        prev_suggestion_lines = 0

        # === B∆∞·ªõc 4: T√≠nh v·ªã tr√≠ cursor trong text ===
        cursor_pos = prompt_vis + cursor
        cursor_line = cursor_pos // term_w
        cursor_col = cursor_pos % term_w

        # T√≠nh end_line (d√≤ng v·∫≠t l√Ω cu·ªëi c√πng sau khi vi·∫øt text)
        if total_visible == 0:
            end_line = 0
        elif total_visible % term_w == 0:
            end_line = total_visible // term_w
        else:
            end_line = (total_visible - 1) // term_w

        # === B∆∞·ªõc 5: Hi·ªÉn th·ªã g·ª£i √Ω (tr∆∞·ªõc khi di chuy·ªÉn cursor v·ªÅ v·ªã tr√≠ ƒë√∫ng) ===
        # L√∫c n√†y cursor ƒëang ·ªü cu·ªëi text (end_line).
        # Vi·∫øt suggestions xu·ªëng ph√≠a d∆∞·ªõi, r·ªìi t·ª± di chuy·ªÉn l√™n cursor_line.
        suggestions = _get_suggestions(text) if text.startswith("/") else []
        n_sugg = len(suggestions)
        prev_suggestion_lines = n_sugg

        if suggestions:
            for s in suggestions:
                sys.stdout.write(f"\r\n  {C.DIM}{s}{C.RESET}")
            # B√¢y gi·ªù cursor ·ªü d√≤ng end_line + n_sugg
            # C·∫ßn quay v·ªÅ cursor_line
            total_up = (end_line - cursor_line) + n_sugg
            if total_up > 0:
                sys.stdout.write(f"\033[{total_up}A")
        else:
            # Kh√¥ng c√≥ suggestion, ch·ªâ c·∫ßn di chuy·ªÉn t·ª´ end_line v·ªÅ cursor_line
            lines_up = end_line - cursor_line
            if lines_up > 0:
                sys.stdout.write(f"\033[{lines_up}A")
            elif lines_up < 0:
                sys.stdout.write(f"\033[{-lines_up}B")

        # Di chuy·ªÉn v·ªÅ c·ªôt ƒë√∫ng
        if cursor_col > 0:
            sys.stdout.write(f"\r\033[{cursor_col}C")
        else:
            sys.stdout.write("\r")

        _cursor_phys_line[0] = cursor_line

        sys.stdout.flush()

    try:
        tty.setraw(fd)

        # In prompt ban ƒë·∫ßu
        sys.stdout.write(prompt)
        sys.stdout.flush()

        while True:
            # ƒê·ªçc 1 byte
            ch = os.read(fd, 1)

            if ch == b'\r' or ch == b'\n':
                # Enter ‚Üí submit
                # Di chuy·ªÉn con tr·ªè xu·ªëng cu·ªëi text, x√≥a h·∫øt ph√≠a d∆∞·ªõi
                term_w = _get_term_width()
                prompt_vis = _visible_len(prompt)
                total_vis = prompt_vis + len(buf)
                if total_vis == 0:
                    end_line = 0
                elif total_vis % term_w == 0:
                    end_line = total_vis // term_w
                else:
                    end_line = (total_vis - 1) // term_w
                down = end_line - _cursor_phys_line[0]
                if down > 0:
                    sys.stdout.write(f"\033[{down}B")
                sys.stdout.write("\033[J\r\n")  # x√≥a t·ª´ cursor ƒë·∫øn h·∫øt m√†n h√¨nh + xu·ªëng d√≤ng
                sys.stdout.flush()
                result = "".join(buf)
                if result.strip():
                    history.append(result)
                return result

            elif ch == b'\x03':
                # Ctrl+C
                term_w = _get_term_width()
                prompt_vis = _visible_len(prompt)
                total_vis = prompt_vis + len(buf)
                if total_vis == 0:
                    end_line = 0
                elif total_vis % term_w == 0:
                    end_line = total_vis // term_w
                else:
                    end_line = (total_vis - 1) // term_w
                down = end_line - _cursor_phys_line[0]
                if down > 0:
                    sys.stdout.write(f"\033[{down}B")
                sys.stdout.write("\033[J\r\n")
                sys.stdout.flush()
                raise KeyboardInterrupt

            elif ch == b'\x04':
                # Ctrl+D (EOF)
                term_w = _get_term_width()
                prompt_vis = _visible_len(prompt)
                total_vis = prompt_vis + len(buf)
                if total_vis == 0:
                    end_line = 0
                elif total_vis % term_w == 0:
                    end_line = total_vis // term_w
                else:
                    end_line = (total_vis - 1) // term_w
                down = end_line - _cursor_phys_line[0]
                if down > 0:
                    sys.stdout.write(f"\033[{down}B")
                sys.stdout.write("\033[J\r\n")
                sys.stdout.flush()
                raise EOFError

            elif ch == b'\x7f' or ch == b'\x08':
                # Backspace
                if cursor > 0:
                    buf.pop(cursor - 1)
                    cursor -= 1
                    _redraw()

            elif ch == b'\t':
                # Tab ‚Üí ch·ªçn g·ª£i √Ω ƒë·∫ßu ti√™n
                text = "".join(buf)
                suggestions = _get_suggestions(text) if text.startswith("/") else []
                if suggestions:
                    # L·∫•y text th·∫≠t t·ª´ suggestion (b·ªè ANSI + ph·∫ßn m√¥ t·∫£)
                    import re
                    raw = re.sub(r'\033\[[^m]*m', '', suggestions[0])
                    # N·∫øu c√≥ ph·∫ßn "  (model_id)" th√¨ ch·ªâ l·∫•y ph·∫ßn tr∆∞·ªõc
                    if "  (" in raw:
                        raw = raw[:raw.index("  (")]
                    buf = list(raw)
                    cursor = len(buf)
                    _redraw()

            elif ch == b'\x1b':
                # Escape sequence (arrows, etc.)
                # ƒê·ªçc th√™m 2 byte
                if _select.select([fd], [], [], 0.05)[0]:
                    seq1 = os.read(fd, 1)
                    if seq1 == b'[' and _select.select([fd], [], [], 0.05)[0]:
                        seq2 = os.read(fd, 1)
                        if seq2 == b'A':
                            # ‚Üë Arrow Up ‚Äî history previous
                            if hist_idx > 0:
                                if hist_idx == len(history):
                                    saved_buf = list(buf)
                                hist_idx -= 1
                                buf = list(history[hist_idx])
                                cursor = len(buf)
                                _redraw()
                        elif seq2 == b'B':
                            # ‚Üì Arrow Down ‚Äî history next
                            if hist_idx < len(history):
                                hist_idx += 1
                                if hist_idx == len(history):
                                    buf = saved_buf if saved_buf is not None else []
                                else:
                                    buf = list(history[hist_idx])
                                cursor = len(buf)
                                _redraw()
                        elif seq2 == b'C':
                            # ‚Üí Arrow Right
                            if cursor < len(buf):
                                cursor += 1
                                _redraw()
                        elif seq2 == b'D':
                            # ‚Üê Arrow Left
                            if cursor > 0:
                                cursor -= 1
                                _redraw()
                        elif seq2 == b'3':
                            # Delete key (ESC [ 3 ~)
                            if _select.select([fd], [], [], 0.05)[0]:
                                os.read(fd, 1)  # consume '~'
                            if cursor < len(buf):
                                buf.pop(cursor)
                                _redraw()
                        elif seq2 == b'H':
                            # Home
                            cursor = 0
                            _redraw()
                        elif seq2 == b'F':
                            # End
                            cursor = len(buf)
                            _redraw()
                    else:
                        pass  # Unknown escape
                else:
                    pass  # Single ESC

            elif ch >= b' ':
                # Printable character (bao g·ªìm UTF-8 multi-byte)
                # X·ª≠ l√Ω UTF-8
                byte = ch[0]
                if byte < 0x80:
                    char = ch.decode('utf-8')
                elif byte < 0xE0:
                    char = (ch + os.read(fd, 1)).decode('utf-8', errors='replace')
                elif byte < 0xF0:
                    char = (ch + os.read(fd, 2)).decode('utf-8', errors='replace')
                else:
                    char = (ch + os.read(fd, 3)).decode('utf-8', errors='replace')

                buf.insert(cursor, char)
                cursor += 1
                _redraw()

    finally:
        termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# SYSTEM PROMPT
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
SYSTEM_PROMPT = (
    "You are a highly sophisticated automated coding agent with expert-level knowledge "
    "across many different programming languages and frameworks.\n"
    "The user will ask a question, or ask you to perform a task, and it may require lots of "
    "research to answer correctly. There is a selection of tools that let you perform actions "
    "or retrieve helpful context to answer the user's question.\n"
    "If you can infer the project type (languages, frameworks, and libraries) from the user's "
    "query or the context that you have, make sure to keep them in mind when making changes.\n"
    "If the user wants you to implement a feature and they have not specified the files to edit, "
    "first break down the user's request into smaller concepts and think about the kinds of files "
    "you need to grasp each concept.\n"
    "If you aren't sure which tool is relevant, you can call multiple tools. You can call tools "
    "repeatedly to take actions or gather as much context as needed until you have completed the "
    "task fully. Don't give up unless you are sure the request cannot be fulfilled with the tools "
    "you have. It's YOUR RESPONSIBILITY to make sure that you have done all you can to collect "
    "necessary context.\n"
    "Don't make assumptions about the situation ‚Äî gather context first, then perform the task "
    "or answer the question.\n"
    "Think creatively and explore the workspace in order to make a complete fix.\n"
    "Don't repeat yourself after a tool call, pick up where you left off.\n"
    "NEVER print out a codeblock with file changes unless the user asked for it. Use the "
    "appropriate file tool instead.\n"
    "NEVER print out a codeblock with a terminal command to run unless the user asked for it. "
    "Use the execute_command tool instead.\n\n"
    "<toolUseInstructions>\n"
    "When using a tool, follow the JSON schema very carefully and make sure to include ALL "
    "required properties.\n"
    "No need to ask permission before using a tool.\n"
    "NEVER say the name of a tool to a user.\n"
    "If you think running multiple tools can answer the user's question, prefer calling them "
    "in parallel whenever possible.\n"
    "Don't call the execute_command tool multiple times in parallel. Instead, run one command "
    "and wait for the output before running the next command.\n"
    "NEVER try to edit a file by running terminal commands unless the user specifically asks "
    "for it.\n"
    "</toolUseInstructions>\n\n"
    "<outputFormatting>\n"
    "Use proper Markdown formatting in your answers.\n"
    "Keep your answers short and impersonal.\n"
    "You are working on a Linux machine.\n"
    "</outputFormatting>"
)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# COPILOT CLIENT
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
class CopilotClient:
    def __init__(self):
        self.github_token = None
        self.copilot_token = None
        self.copilot_token_expires = 0
        self.api_base = None
        self.models = []
        self.selected_model = None
        self.messages = []
        self.system_prompt = SYSTEM_PROMPT
        self.session = requests.Session()
        self.session.headers.update({"User-Agent": USER_AGENT})
        self.mcp_manager = MCPManager() if MCPManager else None

        # Persistent session identifiers (like VS Code)
        self.session_id = f"{uuid.uuid4()}{int(time.time() * 1000)}"
        self.machine_id = hashlib.sha256(uuid.getnode().to_bytes(6, 'big')).hexdigest()

    # ‚îÄ‚îÄ‚îÄ Authentication ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    def set_github_token(self, token: str):
        """Set GitHub token (gho_xxx)."""
        self.github_token = token.strip()

    def fetch_copilot_token(self) -> bool:
        """L·∫•y Copilot token t·ª´ GitHub API."""
        if not self.github_token:
            print(f"{C.RED}[!] Ch∆∞a c√≥ GitHub token.{C.RESET}")
            return False

        url = f"{GITHUB_API}{COPILOT_TOKEN_ENDPOINT}"
        headers = {
            "Authorization": f"token {self.github_token}",
            "X-GitHub-Api-Version": GITHUB_API_VERSION,
            "User-Agent": USER_AGENT,
        }

        try:
            resp = self.session.get(url, headers=headers, timeout=15)

            if resp.status_code != 200:
                print(f"{C.RED}[!] L·∫•y token th·∫•t b·∫°i (HTTP {resp.status_code}){C.RESET}")
                print(f"{C.RED}[!] Response Body:{C.RESET}")
                print(f"{C.RED}{resp.text}{C.RESET}")
                return False

            data = resp.json()
            self.copilot_token = data.get("token")
            self.copilot_token_expires = data.get("expires_at", 0)
            self.api_base = data.get("endpoints", {}).get("api", "https://api.individual.githubcopilot.com")

            if not self.copilot_token:
                print(f"{C.RED}[!] Kh√¥ng t√¨m th·∫•y token trong response.{C.RESET}")
                return False

            # Hi·ªÉn th·ªã th√¥ng tin
            sku = data.get("sku", "unknown")
            chat_enabled = data.get("chat_enabled", False)
            print(f"{C.GREEN}[+] L·∫•y Copilot token th√†nh c√¥ng!{C.RESET}")
            print(f"    SKU: {C.CYAN}{sku}{C.RESET}")
            print(f"    Chat: {C.CYAN}{chat_enabled}{C.RESET}")
            print(f"    API: {C.CYAN}{self.api_base}{C.RESET}")
            exp_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(self.copilot_token_expires))
            print(f"    Expires: {C.CYAN}{exp_time}{C.RESET}")
            return True

        except requests.exceptions.RequestException as e:
            print(f"{C.RED}[!] L·ªói k·∫øt n·ªëi: {e}{C.RESET}")
            return False

    def is_token_valid(self) -> bool:
        """Ki·ªÉm tra token c√≤n h·∫°n kh√¥ng."""
        if not self.copilot_token:
            return False
        return time.time() < self.copilot_token_expires - 60  # 1 ph√∫t buffer

    def ensure_token(self) -> bool:
        """ƒê·∫£m b·∫£o token c√≤n h·∫°n, refresh n·∫øu c·∫ßn."""
        if self.is_token_valid():
            return True
        print(f"{C.YELLOW}[*] Token h·∫øt h·∫°n, ƒëang refresh...{C.RESET}")
        return self.fetch_copilot_token()

    # ‚îÄ‚îÄ‚îÄ Models ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    def fetch_models(self) -> bool:
        """L·∫•y danh s√°ch models."""
        if not self.ensure_token():
            return False

        url = f"{self.api_base}/models"
        headers = {
            "Authorization": f"Bearer {self.copilot_token}",
            "X-Request-Id": f"models-{int(time.time())}",
            "X-Interaction-Type": "model-access",
            "OpenAI-Intent": "model-access",
            "X-GitHub-Api-Version": COPILOT_API_VERSION,
            "Editor-Plugin-Version": "copilot-chat/0.31.5",
            "Editor-Version": "vscode/1.104.1",
            "Copilot-Integration-Id": "vscode-chat",
            "User-Agent": USER_AGENT,
        }

        try:
            resp = self.session.get(url, headers=headers, timeout=15)
            if resp.status_code != 200:
                print(f"{C.RED}[!] L·∫•y models th·∫•t b·∫°i (HTTP {resp.status_code}){C.RESET}")
                return False

            data = resp.json()
            self.models = data.get("data", [])

            # Build index ngay khi fetch
            ordered = self._get_chat_models_ordered()
            self._model_index = {str(i): m.get("id") for i, m in enumerate(ordered, 1)}
            # C·∫≠p nh·∫≠t cho autocomplete
            global _model_ids_for_complete
            _model_ids_for_complete = [m.get("id", "") for m in ordered]

            return True

        except requests.exceptions.RequestException as e:
            print(f"{C.RED}[!] L·ªói k·∫øt n·ªëi: {e}{C.RESET}")
            return False

    def _get_chat_models_ordered(self) -> list[dict]:
        """L·∫•y danh s√°ch chat models theo th·ª© t·ª± hi·ªÉn th·ªã (lightweight ‚Üí versatile ‚Üí powerful ‚Üí other)."""
        chat_models = [
            m for m in self.models
            if m.get("model_picker_enabled", False)
            and m.get("capabilities", {}).get("type") == "chat"
        ]
        categories = {}
        for m in chat_models:
            cat = m.get("model_picker_category", "other")
            categories.setdefault(cat, []).append(m)

        ordered = []
        for cat in ["lightweight", "versatile", "powerful", "other"]:
            ordered.extend(categories.get(cat, []))
        return ordered

    def display_models(self):
        """Hi·ªÉn th·ªã danh s√°ch models ƒë·∫πp v·ªõi s·ªë th·ª© t·ª±."""
        if not self.models:
            if not self.fetch_models():
                return

        ordered = self._get_chat_models_ordered()
        if not ordered:
            print(f"{C.YELLOW}[!] Kh√¥ng t√¨m th·∫•y model n√†o.{C.RESET}")
            return

        # L∆∞u mapping s·ªë ‚Üí model_id cho /select
        self._model_index = {str(i): m.get("id") for i, m in enumerate(ordered, 1)}

        # Nh√≥m theo category
        categories = {}
        for m in ordered:
            cat = m.get("model_picker_category", "other")
            categories.setdefault(cat, []).append(m)

        cat_labels = {
            "lightweight": "‚ö° Lightweight (Nhanh)",
            "versatile":   "üîÑ Versatile (ƒêa nƒÉng)",
            "powerful":    "üöÄ Powerful (M·∫°nh m·∫Ω)",
            "other":       "üì¶ Other",
        }

        print()
        print(f"{C.BOLD}{C.CYAN}{'‚ïê' * 80}{C.RESET}")
        print(f"{C.BOLD}{C.CYAN}  üìã DANH S√ÅCH MODELS C√ì S·∫¥N{C.RESET}")
        print(f"{C.BOLD}{C.CYAN}{'‚ïê' * 80}{C.RESET}")

        idx = 1
        for cat in ["lightweight", "versatile", "powerful", "other"]:
            if cat not in categories:
                continue
            print()
            print(f"  {C.BOLD}{C.YELLOW}{cat_labels.get(cat, cat)}{C.RESET}")
            print(f"  {'‚îÄ' * 76}")

            for m in categories[cat]:
                model_id = m.get("id", "")
                name = m.get("name", "")
                vendor = m.get("vendor", "")
                is_premium = m.get("billing", {}).get("is_premium", False)
                multiplier = m.get("billing", {}).get("multiplier", 0)
                is_preview = m.get("preview", False)
                is_default = m.get("is_chat_default", False)
                supports_thinking = m.get("capabilities", {}).get("supports", {}).get("adaptive_thinking", False) or \
                                    m.get("capabilities", {}).get("supports", {}).get("max_thinking_budget", 0) > 0
                max_ctx = m.get("capabilities", {}).get("limits", {}).get("max_context_window_tokens", 0)
                max_out = m.get("capabilities", {}).get("limits", {}).get("max_output_tokens", 0)

                # Tags
                tags = []
                if is_default:
                    tags.append(f"{C.GREEN}DEFAULT{C.RESET}")
                if is_preview:
                    tags.append(f"{C.MAGENTA}PREVIEW{C.RESET}")
                if is_premium:
                    tags.append(f"{C.YELLOW}PREMIUM x{multiplier}{C.RESET}")
                else:
                    tags.append(f"{C.GREEN}FREE{C.RESET}")
                if supports_thinking:
                    tags.append("üß†")

                tag_str = " ".join(tags)

                # Context size in K
                ctx_k = f"{max_ctx // 1000}K" if max_ctx else "?"
                out_k = f"{max_out // 1000}K" if max_out else "?"

                # Marker cho model ƒëang ch·ªçn
                marker = f"{C.GREEN}‚ñ∫" if self.selected_model and self.selected_model == model_id else " "

                # S·ªë th·ª© t·ª±
                num = f"{C.DIM}{idx:>2}.{C.RESET}"

                print(f"  {marker}{num} {C.BOLD}{C.WHITE}{model_id}{C.RESET}")
                print(f"       {C.DIM}{name} | {vendor} | ctx:{ctx_k} out:{out_k}{C.RESET}  {tag_str}")
                idx += 1

        print()
        print(f"{C.BOLD}{C.CYAN}{'‚ïê' * 80}{C.RESET}")
        print(f"  {C.DIM}D√πng /select <s·ªë> ho·∫∑c /select <model_id> ƒë·ªÉ ch·ªçn model.{C.RESET}")
        print(f"  {C.DIM}VD: /select 1  ho·∫∑c  /select gpt-4o{C.RESET}")
        print()

    def select_model(self, model_id: str) -> bool:
        """Ch·ªçn model theo ID ho·∫∑c s·ªë th·ª© t·ª±."""
        if not self.models:
            self.fetch_models()

        # N·∫øu nh·∫≠p s·ªë ‚Üí tra b·∫£ng index
        model_id = model_id.strip()
        index_map = getattr(self, "_model_index", {})
        if model_id.isdigit() and model_id in index_map:
            model_id = index_map[model_id]

        # T√¨m model
        found = None
        for m in self.models:
            if m.get("id") == model_id:
                found = m
                break

        # Fuzzy match
        if not found:
            for m in self.models:
                if model_id.lower() in m.get("id", "").lower():
                    found = m
                    break

        if not found:
            print(f"{C.RED}[!] Kh√¥ng t√¨m th·∫•y model: {model_id}{C.RESET}")
            print(f"{C.DIM}    D√πng /models ƒë·ªÉ xem danh s√°ch.{C.RESET}")
            return False

        # Ki·ªÉm tra c√≥ ph·∫£i chat model kh√¥ng
        if found.get("capabilities", {}).get("type") != "chat":
            print(f"{C.RED}[!] Model '{model_id}' kh√¥ng h·ªó tr·ª£ chat.{C.RESET}")
            return False

        self.selected_model = found.get("id")
        name = found.get("name", "")
        vendor = found.get("vendor", "")
        print(f"{C.GREEN}[+] ƒê√£ ch·ªçn model: {C.BOLD}{self.selected_model}{C.RESET}")
        print(f"    {C.DIM}{name} | {vendor}{C.RESET}")
        return True

    def display_model_info(self):
        """Hi·ªÉn th·ªã th√¥ng tin model ƒëang d√πng."""
        if not self.selected_model:
            print(f"{C.YELLOW}[!] Ch∆∞a ch·ªçn model. D√πng /select <s·ªë|id>{C.RESET}")
            return

        found = None
        for m in self.models:
            if m.get("id") == self.selected_model:
                found = m
                break

        if not found:
            print(f"{C.YELLOW}[!] Kh√¥ng t√¨m th·∫•y th√¥ng tin model.{C.RESET}")
            return

        caps = found.get("capabilities", {})
        limits = caps.get("limits", {})
        supports = caps.get("supports", {})
        billing = found.get("billing", {})

        print()
        print(f"{C.BOLD}{C.CYAN}{'‚ïê' * 60}{C.RESET}")
        print(f"  {C.BOLD}Model: {C.WHITE}{found.get('name', '')}{C.RESET}")
        print(f"  {C.DIM}ID: {found.get('id', '')}{C.RESET}")
        print(f"{C.CYAN}{'‚îÄ' * 60}{C.RESET}")
        print(f"  Vendor:          {found.get('vendor', '')}")
        print(f"  Version:         {found.get('version', '')}")
        print(f"  Preview:         {found.get('preview', False)}")
        print(f"  Premium:         {billing.get('is_premium', False)} (x{billing.get('multiplier', 0)})")
        print(f"  Context Window:  {limits.get('max_context_window_tokens', '?'):,} tokens")
        print(f"  Max Output:      {limits.get('max_output_tokens', '?'):,} tokens")
        print(f"  Max Prompt:      {limits.get('max_prompt_tokens', '?'):,} tokens")
        print(f"  Vision:          {supports.get('vision', False)}")
        print(f"  Tool Calls:      {supports.get('tool_calls', False)}")
        print(f"  Streaming:       {supports.get('streaming', False)}")
        print(f"  Thinking:        {supports.get('max_thinking_budget', 0) > 0}")
        print(f"{C.BOLD}{C.CYAN}{'‚ïê' * 60}{C.RESET}")
        print()

    # ‚îÄ‚îÄ‚îÄ Chat ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    def chat(self, user_message: str) -> str:
        """G·ª≠i tin nh·∫Øn v√† nh·∫≠n ph·∫£n h·ªìi (streaming + tool calling)."""
        if not self.ensure_token():
            return "[L·ªói] Token kh√¥ng h·ª£p l·ªá."

        if not self.selected_model:
            return "[L·ªói] Ch∆∞a ch·ªçn model. D√πng /select <s·ªë|id>"

        # Th√™m message c·ªßa user
        self.messages.append({"role": "user", "content": user_message})

        # T·∫°o IDs cho to√†n b·ªô interaction n√†y (gi·ªëng VS Code)
        # X-Request-Id: gi·ªØ nguy√™n qua t·∫•t c·∫£ rounds ‚Üí server t√≠nh 1 premium request
        # X-Interaction-Id: unique per interaction (d√πng cho tracking)
        interaction_request_id = str(uuid.uuid4())
        interaction_id = str(uuid.uuid4())

        # Tool calling loop - AI c√≥ th·ªÉ g·ªçi nhi·ªÅu tools li√™n ti·∫øp
        max_tool_rounds = 30
        consecutive_errors = 0
        max_consecutive_errors = 3
        for _round in range(max_tool_rounds):
            result = self._send_chat_request(
                request_id=interaction_request_id,
                interaction_id=interaction_id,
                round_number=_round,
            )
            if result is None:
                return ""

            full_content, tool_calls = result

            # N·∫øu kh√¥ng c√≥ tool calls, ƒë√£ xong
            if not tool_calls:
                if full_content:
                    self.messages.append({"role": "assistant", "content": full_content})
                return full_content

            # C√≥ tool calls ‚Üí th·ª±c thi v√† g·ª≠i l·∫°i
            # Th√™m assistant message v·ªõi tool_calls
            assistant_msg = {"role": "assistant", "content": full_content or None, "tool_calls": tool_calls}
            self.messages.append(assistant_msg)

            # Th·ª±c thi t·ª´ng tool call
            round_had_error = False
            for tc in tool_calls:
                tc_id = tc.get("id", "")
                func = tc.get("function", {})
                func_name = func.get("name", "")
                func_args_str = func.get("arguments", "{}")

                try:
                    func_args = json.loads(func_args_str)
                except json.JSONDecodeError:
                    func_args = {}

                print(f"\n  {C.YELLOW}üîß G·ªçi tool: {C.BOLD}{func_name}{C.RESET}")
                # Debug: lu√¥n hi·ªÉn th·ªã raw args string
                print(f"     {C.DIM}[args_raw] {repr(func_args_str[:300])}{C.RESET}")
                if func_args:
                    # Hi·ªÉn th·ªã args ng·∫Øn g·ªçn
                    args_display = json.dumps(func_args, ensure_ascii=False)
                    if len(args_display) > 200:
                        args_display = args_display[:197] + "..."
                    print(f"     {C.DIM}{args_display}{C.RESET}")
                else:
                    # Debug: show raw args string if parsing failed or empty
                    print(f"     {C.RED}[DEBUG] raw args: {repr(func_args_str[:200])}{C.RESET}")

                # G·ªçi MCP tool
                if self.mcp_manager:
                    tool_result = self.mcp_manager.execute_tool(func_name, func_args)
                else:
                    tool_result = "[L·ªói] MCP Manager ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o"

                # Hi·ªÉn th·ªã k·∫øt qu·∫£ ng·∫Øn g·ªçn
                result_preview = tool_result[:200] + "..." if len(tool_result) > 200 else tool_result
                print(f"     {C.DIM}‚Üí {result_preview}{C.RESET}")

                # Track errors
                if "[Tool Error]" in tool_result or "[L·ªói]" in tool_result:
                    round_had_error = True

                # Truncate tool result n·∫øu qu√° d√†i ƒë·ªÉ ti·∫øt ki·ªám token
                # (gi·ªØ ƒë·∫ßu + ƒëu√¥i ƒë·ªÉ AI c√≥ context ƒë·ªß)
                max_tool_result = 15000  # ~4K tokens
                if len(tool_result) > max_tool_result:
                    keep_head = int(max_tool_result * 0.7)
                    keep_tail = int(max_tool_result * 0.25)
                    tool_result = (
                        tool_result[:keep_head]
                        + f"\n\n... [truncated {len(tool_result) - keep_head - keep_tail} chars] ...\n\n"
                        + tool_result[-keep_tail:]
                    )

                # Th√™m tool result v√†o messages
                self.messages.append({
                    "role": "tool",
                    "tool_call_id": tc_id,
                    "content": tool_result,
                })

            # Track consecutive errors ‚Äî stop n·∫øu model c·ª© g·ªçi tool sai li√™n t·ª•c
            if round_had_error:
                consecutive_errors += 1
                if consecutive_errors >= max_consecutive_errors:
                    print(f"\n{C.RED}[!] D·ª´ng: {consecutive_errors} l·∫ßn tool call li√™n ti·∫øp b·ªã l·ªói.{C.RESET}")
                    self.messages.append({"role": "assistant", "content": full_content or "[Tool calling failed repeatedly]"})
                    return full_content or ""
            else:
                consecutive_errors = 0

            # Ti·∫øp t·ª•c v√≤ng l·∫∑p ƒë·ªÉ AI x·ª≠ l√Ω k·∫øt qu·∫£ tool
            print(f"\n{C.BLUE}ü§ñ Copilot:{C.RESET}")

        return full_content or ""

    def _estimate_tokens(self, text: str) -> int:
        """∆Ø·ªõc t√≠nh s·ªë tokens (1 token ‚âà 4 chars ti·∫øng Anh, 2 chars ti·∫øng Vi·ªát/CJK)."""
        if not text:
            return 0
        return len(text) // 3  # conservative estimate

    @staticmethod
    def _split_concat_json(s: str) -> list:
        """Split concatenated JSON objects: '{"a":1}{"b":2}' ‚Üí ['{"a":1}', '{"b":2}']
        
        Handles Gemini's quirk of merging parallel tool calls into one string.
        Uses a simple brace-depth counter (ignores strings for speed).
        """
        objects = []
        depth = 0
        start = None
        in_string = False
        escape = False

        for i, ch in enumerate(s):
            if escape:
                escape = False
                continue
            if ch == '\\' and in_string:
                escape = True
                continue
            if ch == '"' and not escape:
                in_string = not in_string
                continue
            if in_string:
                continue
            if ch == '{':
                if depth == 0:
                    start = i
                depth += 1
            elif ch == '}':
                depth -= 1
                if depth == 0 and start is not None:
                    objects.append(s[start:i + 1])
                    start = None

        return objects

    def _trim_messages_for_context(self, messages: list, max_tokens: int = 100000) -> list:
        """C·∫Øt b·ªõt messages c≈© n·∫øu t·ªïng tokens v∆∞·ª£t ng∆∞·ª°ng.
        
        Gi·ªØ l·∫°i: message ƒë·∫ßu (user prompt g·ªëc) + N messages cu·ªëi (context g·∫ßn nh·∫•t).
        Truncate tool results d√†i trong messages c≈©.
        """
        # T√≠nh t·ªïng tokens
        total = sum(self._estimate_tokens(
            m.get("content", "") or json.dumps(m.get("tool_calls", []))
        ) for m in messages)

        if total <= max_tokens:
            return messages

        # Strategy: truncate tool results c≈© tr∆∞·ªõc, sau ƒë√≥ x√≥a messages c≈©
        result = list(messages)

        # Pass 1: Truncate old tool results (gi·ªØ 500 chars ƒë·∫ßu)
        for i, m in enumerate(result[:-10]):  # Kh√¥ng truncate 10 messages cu·ªëi
            if m.get("role") == "tool":
                content = m.get("content", "")
                if len(content) > 800:
                    result[i] = dict(m)
                    result[i]["content"] = content[:500] + "\n... [truncated for context] ..."

        # Recalculate
        total = sum(self._estimate_tokens(
            m.get("content", "") or json.dumps(m.get("tool_calls", []))
        ) for m in result)

        if total <= max_tokens:
            return result

        # Pass 2: Drop oldest conversation turns (keep first user msg + last N)
        keep_last = 20
        if len(result) > keep_last + 2:
            # Keep first user message + separator + last N
            trimmed = (
                result[:1]  # first message
                + [{"role": "user", "content": "[... earlier conversation truncated for context ...]"}]
                + result[-keep_last:]  # recent messages
            )
            return trimmed

        return result

    def _send_chat_request(self, request_id=None, interaction_id=None, round_number=0):
        """G·ª≠i m·ªôt request chat v√† tr·∫£ v·ªÅ (content, tool_calls) ho·∫∑c None n·∫øu l·ªói."""
        # Build system prompt ‚Äî inject MCP tools description n·∫øu c√≥
        effective_system = self.system_prompt

        if self.mcp_manager and self.mcp_manager.servers:
            # Inject tool capability summary v√†o system prompt
            # Explicit descriptions gi√∫p model hi·ªÉu khi n√†o d√πng tool n√†o
            tool_summary = {
                "read_text_file": "Read file contents from disk",
                "write_file": "Create or overwrite a file with content",
                "edit_file": "Edit an existing file (partial changes)",
                "list_directory": "List files/folders in a directory",
                "search_files": "Search for files matching a pattern",
                "fetch": "Fetch main content from a URL. Useful for summarizing or analyzing web pages, searching the web, or calling APIs",
                "execute_command": "Run shell commands (bash, python, curl, etc.)",
            }
            tool_lines = []
            for handle in self.mcp_manager.servers.values():
                for tool in handle["tools"]:
                    t_name = tool.get("name", "")
                    if t_name in (self.mcp_manager.tool_map or {}):
                        desc = tool_summary.get(t_name, "")
                        tool_lines.append(f"- **{t_name}**: {desc}" if desc else f"- {t_name}")
            if tool_lines:
                effective_system += (
                    "\n\n## YOUR TOOLS\n"
                    + "\n".join(tool_lines)
                )

        # Trim messages n·∫øu context qu√° d√†i
        trimmed_messages = self._trim_messages_for_context(self.messages)

        # Build messages v·ªõi copilot_cache_control (prompt caching gi·ªëng VS Code)
        # System message: lu√¥n cache
        sys_msg = {
            "role": "system",
            "content": effective_system,
            "copilot_cache_control": {"type": "ephemeral"},
        }
        all_messages = [sys_msg]

        # User/assistant/tool messages: cache t·∫•t c·∫£ tr·ª´ message cu·ªëi c√πng
        for i, m in enumerate(trimmed_messages):
            msg = dict(m)  # shallow copy
            is_last = (i == len(trimmed_messages) - 1)
            # Cache m·ªçi th·ª© tr·ª´ message cu·ªëi (latest user input ho·∫∑c latest tool result)
            if not is_last:
                msg["copilot_cache_control"] = {"type": "ephemeral"}
            all_messages.append(msg)

        body = {
            "messages": all_messages,
            "model": self.selected_model,
            "temperature": 0,
            "top_p": 1,
            "max_tokens": 64000,
            "n": 1,
            "stream": True,
        }

        # Th√™m tools n·∫øu c√≥ MCP
        if self.mcp_manager and self.mcp_manager.servers:
            tools = self.mcp_manager.get_openai_tools()
            if tools:
                body["tools"] = tools
                body["tool_choice"] = "auto"

        url = f"{self.api_base}/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.copilot_token}",
            "X-Request-Id": request_id or str(uuid.uuid4()),
            "X-Interaction-Type": "conversation-agent",
            "OpenAI-Intent": "conversation-agent",
            "X-Interaction-Id": interaction_id or str(uuid.uuid4()),
            "X-Initiator": "user" if round_number == 0 else "agent",
            "VScode-SessionId": self.session_id,
            "VScode-MachineId": self.machine_id,
            "X-GitHub-Api-Version": COPILOT_API_VERSION,
            "Editor-Plugin-Version": "copilot-chat/0.31.5",
            "Editor-Version": "vscode/1.104.1",
            "Copilot-Integration-Id": "vscode-chat",
            "User-Agent": USER_AGENT,
            "Content-Type": "application/json",
        }

        try:
            resp = self.session.post(url, headers=headers, json=body, stream=True, timeout=120)

            if resp.status_code != 200:
                err_text = resp.text[:500]
                print(f"{C.RED}[!] Chat th·∫•t b·∫°i (HTTP {resp.status_code}): {err_text}{C.RESET}")
                self.messages.pop()  # X√≥a message l·ªói
                return None

            # Force UTF-8 encoding ƒë·ªÉ tr√°nh mojibake ti·∫øng Vi·ªát
            resp.encoding = "utf-8"

            # Stream response - d√πng iter_content + t·ª± t√°ch line
            # ƒë·ªÉ x·ª≠ l√Ω UTF-8 multi-byte characters ƒë√∫ng c√°ch
            full_content = ""
            reasoning_text = ""
            showed_reasoning_header = False
            buffer = ""
            tool_calls_acc = {}  # index -> {id, function: {name, arguments}}

            for chunk_bytes in resp.iter_content(chunk_size=None):
                if not chunk_bytes:
                    continue

                # Decode UTF-8 ƒë√∫ng c√°ch
                buffer += chunk_bytes.decode("utf-8", errors="replace")

                # T√°ch theo newline, gi·ªØ l·∫°i ph·∫ßn ch∆∞a ho√†n ch·ªânh
                while "\n" in buffer:
                    line, buffer = buffer.split("\n", 1)
                    line = line.strip()

                    if not line:
                        continue
                    if not line.startswith("data: "):
                        continue

                    data_str = line[6:]  # B·ªè "data: "

                    if data_str.strip() == "[DONE]":
                        buffer = ""
                        break

                    try:
                        chunk = json.loads(data_str)
                    except json.JSONDecodeError:
                        continue

                    choices = chunk.get("choices", [])
                    if not choices:
                        continue

                    delta = choices[0].get("delta", {})

                    # Reasoning text (thinking)
                    r_text = delta.get("reasoning_text")
                    if r_text:
                        if not showed_reasoning_header:
                            print(f"\n{C.DIM}üí≠ Thinking...{C.RESET}")
                            showed_reasoning_header = True
                        reasoning_text += r_text

                    # Tool calls (streaming)
                    delta_tool_calls = delta.get("tool_calls", [])
                    for tc_delta in delta_tool_calls:
                        idx = tc_delta.get("index", 0)

                        # Detect new tool call: n·∫øu c√≥ "id" m·ªõi ‚Üí ƒë√¢y l√† tool call m·ªõi
                        # Gemini c√≥ th·ªÉ g·ª≠i nhi·ªÅu tool calls c√πng index 0
                        # D√πng "id" ƒë·ªÉ ph√¢n bi·ªát tool calls thay v√¨ ch·ªâ d·ª±a v√†o index
                        new_id = tc_delta.get("id", "")
                        if new_id and new_id not in {tc.get("id", "") for tc in tool_calls_acc.values()}:
                            # Tool call m·ªõi ‚Äî t√¨m slot tr·ªëng
                            actual_idx = len(tool_calls_acc)
                            tool_calls_acc[actual_idx] = {
                                "id": new_id,
                                "type": "function",
                                "function": {"name": "", "arguments": ""},
                            }
                            idx = actual_idx
                        elif new_id:
                            # T√¨m idx theo id ƒë√£ t·ªìn t·∫°i
                            for existing_idx, existing_tc in tool_calls_acc.items():
                                if existing_tc.get("id") == new_id:
                                    idx = existing_idx
                                    break
                        else:
                            # Kh√¥ng c√≥ id ‚Üí d√πng index (fallback cho streaming chunks ti·∫øp theo)
                            if idx not in tool_calls_acc:
                                tool_calls_acc[idx] = {
                                    "id": "",
                                    "type": "function",
                                    "function": {"name": "", "arguments": ""},
                                }

                        func_delta = tc_delta.get("function", {})
                        # Name: ch·ªâ set n·∫øu ch∆∞a c√≥ (tool name g·ª≠i 1 l·∫ßn duy nh·∫•t)
                        if func_delta.get("name"):
                            if not tool_calls_acc[idx]["function"]["name"]:
                                tool_calls_acc[idx]["function"]["name"] = func_delta["name"]
                        # Arguments: append v√¨ streaming (JSON g·ª≠i theo t·ª´ng chunk)
                        # D√πng "in" thay v√¨ .get() ƒë·ªÉ catch c·∫£ empty string ""
                        if "arguments" in func_delta and func_delta["arguments"] is not None:
                            tool_calls_acc[idx]["function"]["arguments"] += func_delta["arguments"]

                    # Content text
                    content = delta.get("content")
                    if content:
                        full_content += content
                        sys.stdout.write(content)
                        sys.stdout.flush()

                    # Finish reason
                    finish = choices[0].get("finish_reason")
                    if finish:
                        buffer = ""
                        break

            print()  # Newline sau khi stream xong

            # Build tool_calls list v·ªõi validation
            tool_calls = []
            if tool_calls_acc:
                for idx in sorted(tool_calls_acc.keys()):
                    tc = tool_calls_acc[idx]
                    args_str = tc["function"]["arguments"]
                    tc_name = tc["function"]["name"]

                    # Debug: lu√¥n in raw args ƒë·ªÉ debug
                    if os.environ.get("COPILOT_DEBUG"):
                        print(f"     {C.DIM}[DEBUG] {tc_name} raw_args ({len(args_str)}): {repr(args_str[:500])}{C.RESET}")

                    # Validate arguments l√† valid JSON
                    try:
                        json.loads(args_str)
                        tool_calls.append(tc)
                    except (json.JSONDecodeError, TypeError):
                        # Detect concatenated JSON objects: {"cmd":"a"}{"url":"b"}{"cmd":"c"}
                        # Gemini sometimes merges parallel tool calls into one args string
                        split_objects = self._split_concat_json(args_str)
                        if len(split_objects) > 1:
                            print(f"     {C.YELLOW}[!] T√°ch {len(split_objects)} tool calls b·ªã merge{C.RESET}")
                            for i, obj_str in enumerate(split_objects):
                                try:
                                    obj = json.loads(obj_str)
                                    # Infer tool name t·ª´ keys
                                    inferred_name = tc_name
                                    if "url" in obj:
                                        inferred_name = "fetch"
                                    elif "command" in obj:
                                        inferred_name = "execute_command"
                                    elif "path" in obj and "content" in obj:
                                        inferred_name = "write_file"
                                    elif "path" in obj:
                                        inferred_name = "read_text_file"

                                    split_tc = {
                                        "id": tc["id"] + f"_split{i}" if i > 0 else tc["id"],
                                        "type": "function",
                                        "function": {
                                            "name": inferred_name,
                                            "arguments": obj_str,
                                        },
                                    }
                                    tool_calls.append(split_tc)
                                except json.JSONDecodeError:
                                    pass  # Skip invalid fragments
                        else:
                            print(f"     {C.RED}[!] Tool '{tc_name}' invalid JSON args ({len(args_str)} chars): {repr(args_str[:300])}{C.RESET}")
                            tc["function"]["arguments"] = "{}"
                            tool_calls.append(tc)

            return (full_content, tool_calls)

        except requests.exceptions.RequestException as e:
            print(f"{C.RED}[!] L·ªói k·∫øt n·ªëi: {e}{C.RESET}")
            self.messages.pop()
            return None

    def clear_history(self):
        """X√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i."""
        self.messages.clear()
        print(f"{C.GREEN}[+] ƒê√£ x√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i.{C.RESET}")

    def set_system_prompt(self, prompt: str):
        """Thay ƒë·ªïi system prompt."""
        self.system_prompt = prompt
        print(f"{C.GREEN}[+] ƒê√£ c·∫≠p nh·∫≠t system prompt!{C.RESET}")

    def reset_system_prompt(self):
        """Reset system prompt v·ªÅ m·∫∑c ƒë·ªãnh."""
        self.system_prompt = SYSTEM_PROMPT
        print(f"{C.GREEN}[+] ƒê√£ reset system prompt v·ªÅ m·∫∑c ƒë·ªãnh.{C.RESET}")

    def display_system_prompt(self):
        """Hi·ªÉn th·ªã system prompt hi·ªán t·∫°i."""
        print()
        print(f"{C.BOLD}{C.CYAN}{'‚ïê' * 60}{C.RESET}")
        print(f"  {C.BOLD}üîß SYSTEM PROMPT HI·ªÜN T·∫†I{C.RESET}")
        print(f"{C.CYAN}{'‚îÄ' * 60}{C.RESET}")
        for line in self.system_prompt.split("\n"):
            print(f"  {C.DIM}{line}{C.RESET}")
        print(f"{C.BOLD}{C.CYAN}{'‚ïê' * 60}{C.RESET}")
        print(f"  {C.DIM}D√πng /system set <n·ªôi dung> ƒë·ªÉ thay ƒë·ªïi{C.RESET}")
        print(f"  {C.DIM}D√πng /system reset ƒë·ªÉ reset v·ªÅ m·∫∑c ƒë·ªãnh{C.RESET}")
        print()

    def display_history(self):
        """Hi·ªÉn th·ªã l·ªãch s·ª≠ h·ªôi tho·∫°i."""
        if not self.messages:
            print(f"{C.YELLOW}[!] Ch∆∞a c√≥ l·ªãch s·ª≠ h·ªôi tho·∫°i.{C.RESET}")
            return

        print()
        print(f"{C.BOLD}{C.CYAN}{'‚ïê' * 60}{C.RESET}")
        print(f"  {C.BOLD}üìú L·ªäCH S·ª¨ H·ªòI THO·∫†I ({len(self.messages)} messages){C.RESET}")
        print(f"{C.CYAN}{'‚ïê' * 60}{C.RESET}")

        for i, msg in enumerate(self.messages):
            role = msg["role"]
            content = msg["content"]
            if role == "user":
                print(f"\n  {C.GREEN}üë§ You:{C.RESET}")
            else:
                print(f"\n  {C.BLUE}ü§ñ Copilot:{C.RESET}")

            # Truncate n·∫øu qu√° d√†i
            if len(content) > 300:
                content = content[:300] + "..."
            for line in content.split("\n"):
                print(f"    {line}")

        print(f"\n{C.BOLD}{C.CYAN}{'‚ïê' * 60}{C.RESET}")
        print()


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# HELP
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
def display_help():
    print(f"""
{C.BOLD}{C.CYAN}{'‚ïê' * 60}{C.RESET}
  {C.BOLD}üìñ H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG{C.RESET}
{C.CYAN}{'‚ïê' * 60}{C.RESET}

  {C.YELLOW}/models{C.RESET}          Xem danh s√°ch models c√≥ s·∫µn
  {C.YELLOW}/select <s·ªë|id>{C.RESET}  Ch·ªçn model (VD: /select 1 ho·∫∑c /select gpt-4o)
  {C.YELLOW}/info{C.RESET}            Xem th√¥ng tin model ƒëang d√πng
  {C.YELLOW}/system{C.RESET}          Xem system prompt hi·ªán t·∫°i
  {C.YELLOW}/system set{C.RESET}      Thay ƒë·ªïi system prompt (nh·∫≠p multi-line)
  {C.YELLOW}/system reset{C.RESET}    Reset system prompt v·ªÅ m·∫∑c ƒë·ªãnh
  {C.YELLOW}/clear{C.RESET}           X√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i
  {C.YELLOW}/history{C.RESET}         Xem l·ªãch s·ª≠ h·ªôi tho·∫°i
  {C.YELLOW}/mcp{C.RESET}             Xem danh s√°ch MCP tools ƒëang k·∫øt n·ªëi
  {C.YELLOW}/mcp add <dir>{C.RESET}   Th√™m th∆∞ m·ª•c v√†o MCP Filesystem Server
  {C.YELLOW}/mcp fetch{C.RESET}       Th√™m MCP Fetch Server (t·∫£i web)
  {C.YELLOW}/mcp shell{C.RESET}       Th√™m MCP Shell Server (ch·∫°y l·ªánh terminal)
  {C.YELLOW}/mcp auto{C.RESET}        T·ª± ƒë·ªông th√™m t·∫•t c·∫£ MCP servers
  {C.YELLOW}/mcp stop{C.RESET}        D·ª´ng t·∫•t c·∫£ MCP servers
  {C.YELLOW}/token{C.RESET}           ƒê·ªïi GitHub token
  {C.YELLOW}/refresh{C.RESET}         Refresh Copilot token
  {C.YELLOW}/help{C.RESET}            Xem h∆∞·ªõng d·∫´n n√†y
  {C.YELLOW}/exit{C.RESET}            Tho√°t ch∆∞∆°ng tr√¨nh

  {C.DIM}Nh·∫≠p b·∫•t k·ª≥ n·ªôi dung n√†o kh√°c ƒë·ªÉ chat v·ªõi AI.{C.RESET}

{C.BOLD}{C.CYAN}{'‚ïê' * 60}{C.RESET}
""")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# BANNER
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
def display_banner():
    banner = f"""
{C.BOLD}{C.CYAN}
  ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
  ‚ïë                                                          ‚ïë
  ‚ïë     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ïë
  ‚ïë    ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ïë
  ‚ïë    ‚ñà‚ñà‚ïë      ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ïë
  ‚ïë    ‚ñà‚ñà‚ïë      ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïù ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ïë
  ‚ïë    ‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù   ‚ñà‚ñà‚ïë   ‚ïë
  ‚ïë     ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù    ‚ïö‚ïê‚ïù   ‚ïë
  ‚ïë                                                          ‚ïë
  ‚ïë         GitHub Copilot Chat CLI Tool v1.0                ‚ïë
  ‚ïë                                                          ‚ïë
  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
{C.RESET}"""
    print(banner)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# MAIN
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
def main():
    display_banner()

    client = CopilotClient()

    # ‚îÄ‚îÄ‚îÄ B∆∞·ªõc 1: Nh·∫≠p GitHub Token ‚îÄ‚îÄ‚îÄ
    token_file = os.path.join(os.path.dirname(os.path.abspath(__file__)), "token.txt")
    token = None

    if os.path.isfile(token_file):
        with open(token_file, "r") as f:
            token = f.read().strip()
        if token:
            print(f"{C.GREEN}[+] ƒê√£ t√¨m th·∫•y token.txt, t·ª± ƒë·ªông import token.{C.RESET}")
            print(f"    {C.DIM}{token[:10]}...{token[-4:]}{C.RESET}")
        else:
            token = None

    if not token:
        print(f"{C.BOLD}[B∆∞·ªõc 1] Nh·∫≠p GitHub Token{C.RESET}")
        print(f"{C.DIM}  Token c√≥ d·∫°ng: gho_xxxxxxxxxxxx{C.RESET}")
        print(f"{C.DIM}  (L·∫•y t·ª´ GitHub Copilot extension ho·∫∑c OAuth){C.RESET}")
        print()

        while True:
            try:
                token = input(f"{C.YELLOW}GitHub Token: {C.RESET}").strip()
            except (KeyboardInterrupt, EOFError):
                print(f"\n{C.RED}[!] Bye!{C.RESET}")
                sys.exit(0)

            if not token:
                print(f"{C.RED}[!] Token kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng.{C.RESET}")
                continue
            break

    client.set_github_token(token)

    # ‚îÄ‚îÄ‚îÄ B∆∞·ªõc 2: L·∫•y Copilot Token ‚îÄ‚îÄ‚îÄ
    print()
    print(f"{C.BOLD}[B∆∞·ªõc 2] ƒêang l·∫•y Copilot token...{C.RESET}")
    if not client.fetch_copilot_token():
        print(f"{C.RED}[!] Kh√¥ng th·ªÉ l·∫•y Copilot token. Ki·ªÉm tra l·∫°i GitHub token.{C.RESET}")
        sys.exit(1)

    # ‚îÄ‚îÄ‚îÄ B∆∞·ªõc 3: L·∫•y danh s√°ch Models ‚îÄ‚îÄ‚îÄ
    print()
    print(f"{C.BOLD}[B∆∞·ªõc 3] ƒêang l·∫•y danh s√°ch models...{C.RESET}")
    if client.fetch_models():
        print(f"{C.GREEN}[+] ƒê√£ l·∫•y {len(client.models)} models.{C.RESET}")
    else:
        print(f"{C.YELLOW}[!] Kh√¥ng l·∫•y ƒë∆∞·ª£c danh s√°ch models.{C.RESET}")

    # ‚îÄ‚îÄ‚îÄ B∆∞·ªõc 4: Ch·ªçn Model m·∫∑c ƒë·ªãnh ‚îÄ‚îÄ‚îÄ
    # T·ª± ƒë·ªông ch·ªçn gpt-4o ho·∫∑c model default
    default_model = None
    for m in client.models:
        if m.get("is_chat_default"):
            default_model = m.get("id")
            break

    if not default_model:
        # Fallback: ch·ªçn gpt-4.1 ho·∫∑c gpt-4o
        for mid in ["gpt-4.1", "gpt-4o", "gpt-5-mini"]:
            for m in client.models:
                if m.get("id") == mid:
                    default_model = mid
                    break
            if default_model:
                break

    if default_model:
        client.select_model(default_model)

    print()
    print(f"{C.DIM}  G√µ /help ƒë·ªÉ xem h∆∞·ªõng d·∫´n. G√µ /models ƒë·ªÉ xem danh s√°ch models.{C.RESET}")
    print(f"{C.DIM}  G√µ /select <s·ªë> ho·∫∑c /select <model_id> ƒë·ªÉ ch·ªçn model kh√°c.{C.RESET}")
    print()

    # ‚îÄ‚îÄ‚îÄ Chat Loop ‚îÄ‚îÄ‚îÄ
    while True:
        try:
            # Prompt
            model_label = client.selected_model or "no-model"
            prompt_str = f"{C.BOLD}{C.GREEN}[{model_label}]{C.RESET} {C.BOLD}>{C.RESET} "
            user_input = _smart_input(prompt_str).strip()
        except (KeyboardInterrupt, EOFError):
            print(f"\n{C.GREEN}[+] Bye! üëã{C.RESET}")
            break

        if not user_input:
            continue

        # ‚îÄ‚îÄ‚îÄ Handle Commands ‚îÄ‚îÄ‚îÄ
        if user_input.startswith("/"):
            parts = user_input.split(maxsplit=1)
            cmd = parts[0].lower()
            arg = parts[1] if len(parts) > 1 else ""

            if cmd == "/exit" or cmd == "/quit":
                print(f"{C.GREEN}[+] Bye! üëã{C.RESET}")
                break

            elif cmd == "/models":
                client.display_models()

            elif cmd == "/select":
                if not arg:
                    print(f"{C.YELLOW}[!] D√πng: /select <s·ªë> ho·∫∑c /select <model_id>{C.RESET}")
                    print(f"{C.DIM}    VD: /select 1  ho·∫∑c  /select gpt-4o{C.RESET}")
                else:
                    client.select_model(arg.strip())

            elif cmd == "/info":
                client.display_model_info()

            elif cmd == "/clear":
                client.clear_history()

            elif cmd == "/history":
                client.display_history()

            elif cmd == "/system":
                sub = arg.strip().lower()
                if sub == "reset":
                    client.reset_system_prompt()
                elif sub.startswith("set"):
                    # Cho ph√©p nh·∫≠p multi-line system prompt
                    inline = sub[3:].strip()
                    if inline:
                        # /system set B·∫°n l√† tr·ª£ l√Ω...
                        client.set_system_prompt(arg[3:].strip())
                    else:
                        print(f"{C.YELLOW}Nh·∫≠p system prompt m·ªõi (g√µ d√≤ng tr·ªëng ƒë·ªÉ k·∫øt th√∫c):{C.RESET}")
                        lines = []
                        while True:
                            try:
                                line = input(f"{C.DIM}  | {C.RESET}")
                                if line == "":
                                    break
                                lines.append(line)
                            except (KeyboardInterrupt, EOFError):
                                print()
                                break
                        if lines:
                            client.set_system_prompt("\n".join(lines))
                        else:
                            print(f"{C.YELLOW}[!] Kh√¥ng c√≥ n·ªôi dung, gi·ªØ nguy√™n system prompt.{C.RESET}")
                else:
                    client.display_system_prompt()

            elif cmd == "/help":
                display_help()

            elif cmd == "/token":
                try:
                    new_token = input(f"{C.YELLOW}GitHub Token m·ªõi: {C.RESET}").strip()
                    if new_token:
                        client.set_github_token(new_token)
                        if client.fetch_copilot_token():
                            client.fetch_models()
                except (KeyboardInterrupt, EOFError):
                    print()

            elif cmd == "/refresh":
                client.fetch_copilot_token()

            elif cmd == "/mcp":
                sub = arg.strip().lower()
                if sub.startswith("add"):
                    # /mcp add /path/to/dir
                    dir_path = arg[3:].strip() if len(arg) > 3 else ""
                    if not dir_path:
                        try:
                            dir_path = input(f"{C.YELLOW}ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c: {C.RESET}").strip()
                        except (KeyboardInterrupt, EOFError):
                            print()
                            continue
                    if not dir_path:
                        print(f"{C.YELLOW}[!] C·∫ßn nh·∫≠p ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c.{C.RESET}")
                    elif not client.mcp_manager:
                        print(f"{C.RED}[!] MCP module ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t (thi·∫øu mcp_client.py).{C.RESET}")
                    else:
                        # D·ª´ng server c≈© n·∫øu c√≥
                        if "filesystem" in client.mcp_manager.servers:
                            try:
                                client.mcp_manager._run_async(
                                    client.mcp_manager._disconnect_server(
                                        client.mcp_manager.servers["filesystem"]
                                    )
                                )
                            except Exception:
                                pass
                            del client.mcp_manager.servers["filesystem"]
                            client.mcp_manager.tool_map = {
                                k: v for k, v in client.mcp_manager.tool_map.items()
                                if v != "filesystem"
                            }
                        print(f"{C.BOLD}[MCP] ƒêang kh·ªüi ƒë·ªông Filesystem Server...{C.RESET}")
                        dirs = [d.strip() for d in dir_path.split(",")]
                        if client.mcp_manager.add_filesystem_server(dirs):
                            n_tools = len([
                                t for t in client.mcp_manager.tool_map
                                if client.mcp_manager.tool_map[t] == "filesystem"
                            ])
                            print(f"{C.GREEN}[+] MCP Filesystem Server ƒë√£ k·∫øt n·ªëi! ({n_tools} tools){C.RESET}")
                            client.mcp_manager.display_tools()
                        else:
                            print(f"{C.RED}[!] Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông MCP Filesystem Server.{C.RESET}")

                elif sub == "fetch":
                    if not client.mcp_manager:
                        print(f"{C.RED}[!] MCP module ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t.{C.RESET}")
                    elif "fetch" in client.mcp_manager.servers:
                        print(f"{C.YELLOW}[!] Fetch Server ƒë√£ ƒëang ch·∫°y.{C.RESET}")
                    else:
                        print(f"{C.BOLD}[MCP] ƒêang kh·ªüi ƒë·ªông Fetch Server...{C.RESET}")
                        if client.mcp_manager.add_fetch_server():
                            print(f"{C.GREEN}[+] MCP Fetch Server ƒë√£ k·∫øt n·ªëi!{C.RESET}")
                        else:
                            print(f"{C.RED}[!] Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông MCP Fetch Server.{C.RESET}")
                            print(f"{C.DIM}    C√†i: pip install mcp-server-fetch{C.RESET}")

                elif sub == "shell":
                    if not client.mcp_manager:
                        print(f"{C.RED}[!] MCP module ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t.{C.RESET}")
                    elif "shell" in client.mcp_manager.servers:
                        print(f"{C.YELLOW}[!] Shell Server ƒë√£ ƒëang ch·∫°y.{C.RESET}")
                    else:
                        print(f"{C.BOLD}[MCP] ƒêang kh·ªüi ƒë·ªông Shell Server...{C.RESET}")
                        if client.mcp_manager.add_shell_server():
                            print(f"{C.GREEN}[+] MCP Shell Server ƒë√£ k·∫øt n·ªëi!{C.RESET}")
                        else:
                            print(f"{C.RED}[!] Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông MCP Shell Server.{C.RESET}")
                            print(f"{C.DIM}    C√†i: pip install mcp-server-shell{C.RESET}")

                elif sub == "auto":
                    if not client.mcp_manager:
                        print(f"{C.RED}[!] MCP module ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t.{C.RESET}")
                    else:
                        cwd = os.getcwd()
                        print(f"{C.BOLD}[MCP] ƒêang kh·ªüi ƒë·ªông t·∫•t c·∫£ servers...{C.RESET}")
                        # Filesystem
                        if "filesystem" not in client.mcp_manager.servers:
                            print(f"  üìÅ Filesystem ({cwd})...", end=" ", flush=True)
                            if client.mcp_manager.add_filesystem_server([cwd]):
                                print(f"{C.GREEN}OK{C.RESET}")
                            else:
                                print(f"{C.RED}FAIL{C.RESET}")
                        # Fetch
                        if "fetch" not in client.mcp_manager.servers:
                            print(f"  üåê Fetch...", end=" ", flush=True)
                            if client.mcp_manager.add_fetch_server():
                                print(f"{C.GREEN}OK{C.RESET}")
                            else:
                                print(f"{C.RED}FAIL{C.RESET}")
                        # Shell
                        if "shell" not in client.mcp_manager.servers:
                            print(f"  üíª Shell...", end=" ", flush=True)
                            if client.mcp_manager.add_shell_server():
                                print(f"{C.GREEN}OK{C.RESET}")
                            else:
                                print(f"{C.RED}FAIL{C.RESET}")
                        print()
                        client.mcp_manager.display_tools()
                        n = len(client.mcp_manager.get_openai_tools())
                        print(f"\n  {C.GREEN}T·ªïng c·ªông {n} tools s·∫µn s√†ng.{C.RESET}\n")

                elif sub == "stop":
                    if client.mcp_manager:
                        client.mcp_manager.stop_all()
                        print(f"{C.GREEN}[+] ƒê√£ d·ª´ng t·∫•t c·∫£ MCP servers.{C.RESET}")
                    else:
                        print(f"{C.YELLOW}[!] MCP module ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t.{C.RESET}")

                else:
                    # /mcp ‚Üí hi·ªÉn th·ªã tools
                    print()
                    print(f"{C.BOLD}{C.CYAN}{'‚ïê' * 60}{C.RESET}")
                    print(f"  {C.BOLD}üîå MCP SERVERS & TOOLS{C.RESET}")
                    print(f"{C.CYAN}{'‚îÄ' * 60}{C.RESET}")
                    if client.mcp_manager:
                        client.mcp_manager.display_tools()
                    else:
                        print(f"  {C.YELLOW}MCP module ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t.{C.RESET}")
                    print(f"{C.BOLD}{C.CYAN}{'‚ïê' * 60}{C.RESET}")
                    print(f"  {C.DIM}/mcp add <dir>  - Filesystem Server{C.RESET}")
                    print(f"  {C.DIM}/mcp fetch      - Fetch Server (t·∫£i web){C.RESET}")
                    print(f"  {C.DIM}/mcp shell      - Shell Server (terminal){C.RESET}")
                    print(f"  {C.DIM}/mcp auto       - T·∫•t c·∫£ servers{C.RESET}")
                    print()

            else:
                print(f"{C.YELLOW}[!] L·ªánh kh√¥ng h·ª£p l·ªá: {cmd}{C.RESET}")
                print(f"{C.DIM}    G√µ /help ƒë·ªÉ xem danh s√°ch l·ªánh.{C.RESET}")

            continue

        # ‚îÄ‚îÄ‚îÄ Chat ‚îÄ‚îÄ‚îÄ
        if not client.selected_model:
            print(f"{C.YELLOW}[!] Ch∆∞a ch·ªçn model. D√πng /models ƒë·ªÉ xem v√† /select <s·ªë> ƒë·ªÉ ch·ªçn.{C.RESET}")
            continue

        print()
        print(f"{C.BLUE}ü§ñ Copilot:{C.RESET}")
        client.chat(user_input)
        print()

    # Cleanup MCP servers
    if client.mcp_manager:
        client.mcp_manager.stop_all()


if __name__ == "__main__":
    main()
